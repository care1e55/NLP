{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ot3c4fjZwC4T"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2JdzEXmwRU5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMohh_6CwC4W"
   },
   "source": [
    "### Задача определения частей речи, Part-Of-Speech Tagger (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Aad2tmBwC4Y"
   },
   "source": [
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYYV0mdmwC4f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict, deque\n",
    "from nltk.corpus import brown\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPgI52lRwC4n"
   },
   "source": [
    "Вам в помощь http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxdJxMEAwC4o"
   },
   "source": [
    "Загрузим brown корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZvhXAL_9wC4q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/care1e55/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wto8PSC6wC4v"
   },
   "source": [
    "<b>Существует не одна система тегирования, поэтому будьте внимательны, когда прогнозируете тег слов в тексте и вычисляете качество прогноза. Можете получить несправедливо низкое качество вашего решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJ6tuHA_wC4z"
   },
   "source": [
    "На семинаре была рассмотрена одна система. А сейчас будем использовать универсальную систему тегирования universal_tagset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cht7dImWwC42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/care1e55/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiTimRRywC47"
   },
   "source": [
    "<img src=\"https://4.bp.blogspot.com/-IcFli2wljs0/WrVCw3umY_I/AAAAAAAACYM/UJ_neoUAs3wF95dj2Ouf3BzxXzB_b2TbQCLcBGAs/s1600/postags.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyDBMcBSwC48"
   },
   "source": [
    "Мы имеем массив предложений пар (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BobflewQwC4-",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "brown_tagged_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSu1KqRrwC5L"
   },
   "source": [
    "Первое предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCHCZPlkwC5N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIV2MiRxwC5Q"
   },
   "source": [
    "Все пары (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVx9e9HcwC5R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
    "brown_tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-ADby6LwC5V"
   },
   "source": [
    "Проанализируйте данные, с которыми Вы работаете. Используйте `nltk.FreqDist()` для подсчета частоты встречаемости тега и слова в нашем корпусе. Под частой элемента подразумевается кол-во этого элемента в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzRoXuKFcMZK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Приведем слова к нижнему регистру\n",
    "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4giWaqXjwC5W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во предложений:  57340\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во предложений: ', len(brown_tagged_sents))\n",
    "tags = [tag for (word, tag) in brown_tagged_words] # наши теги\n",
    "words = [word for (word, tag) in brown_tagged_words] # наши слова\n",
    "\n",
    "tag_num = pd.Series(nltk.probability.FreqDist(tag for tag in tags)).sort_values(ascending=False) # тег - кол-во тега в корпусе\n",
    "word_num = pd.Series(nltk.probability.FreqDist(word for word in words)).sort_values(ascending=False) # слово - кол-во слова в корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfiPpCcLwC5Z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN    275558\n",
       "VERB    182750\n",
       ".       147565\n",
       "ADP     144766\n",
       "DET     137019\n",
       "ADJ      83721\n",
       "ADV      56239\n",
       "PRON     49334\n",
       "CONJ     38151\n",
       "PRT      29829\n",
       "NUM      14874\n",
       "X         1386\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Y1huw7TwC5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(tag_num.index, tag_num.values)\n",
    "plt.title(\"Tag_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBbhnJsmwC5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    69971\n",
       ",      58334\n",
       ".      49346\n",
       "of     36412\n",
       "and    28853\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WmEOBMkwC5i"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(word_num.index[:10], word_num.values[:10])\n",
    "plt.title(\"Word_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n08z2PjMwC5o"
   },
   "source": [
    "### Вопрос 1:\n",
    "* Кол-во слова `cat` в корпусе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhB7di3YwC5p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num['cat']\n",
    "23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UsCfVLsewC5s"
   },
   "source": [
    "### Вопрос 2:\n",
    "* Самое популярное слово с самым популярным тегом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nltk.probability.FreqDist(noun for noun in [word for (word, tag) in brown_tagged_words if tag_num.index[0] in (word, tag)[1]])).sort_values(ascending=False).index[0]\n",
    "'time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-OGc1rSwC5x"
   },
   "source": [
    "Впоследствии обучение моделей может занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eb7MhxVRwC5y"
   },
   "source": [
    "Категории нашего корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSiVcP1TwC51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjSlFatJwC53"
   },
   "source": [
    "Будем работать с категорией humor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_f1rl5x0wC55"
   },
   "source": [
    "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GX9t-1qowC58"
   },
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\", categories='humor')\n",
    "# Приведем слова к нижнему регистру\n",
    "my_brown_tagged_sents = []\n",
    "for sent in brown_tagged_sents:\n",
    "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(), x[1]), sent)))\n",
    "\n",
    "my_brown_tagged_sents = np.array(my_brown_tagged_sents)\n",
    "np.random.seed(2)\n",
    "random_index = np.random.choice([0, 1], my_brown_tagged_sents.__len__(), p=[0.1, 0.9]).astype('bool')\n",
    "train_sents = my_brown_tagged_sents[random_index]\n",
    "test_sents = my_brown_tagged_sents[(1 - random_index).astype('bool')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXkVwUjYwC5-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQMjzJ2YwC6C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_rEasLVcwC6G"
   },
   "source": [
    "### Метод максимального правдоподобия для обучения модели\n",
    "\n",
    "* $\\normalsize S = s_0, s_1, ..., s_N$ - скрытые состояния, то есть различные теги\n",
    "* $\\normalsize O = o_0, o_1, ..., o_M$ - различные слова\n",
    "* $\\normalsize a_{i,j} = p(s_j|s_i)$ - вероятность того, что, находясь в скрытом состоянии $s_i$, мы попадем в состояние $s_j$ (элемент матрицы $A$)\n",
    "* $\\normalsize b_{k,j}=p(o_k|s_j)$ - вероятность того, что при скрытом состоянии $s_j$ находится слово $o_k$(элемент матрицы $B$)\n",
    "\n",
    "$$\\normalsize x_t \\in O, y_t \\in S$$\n",
    "$\\normalsize (x_t, y_t)$ - слово и тег, стоящие на месте $t$ $\\Rightarrow$ \n",
    "* $\\normalsize X$ - последовательность слов\n",
    "* $\\normalsize Y$ - последовательность тегов\n",
    "\n",
    "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(y_t | y_{t - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_t | y_t)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(y_0)$ задайте равномерным.\n",
    "\n",
    "Пример $X = [x_0, x_1], Y = [y_0, y_1]$:<br><br>\n",
    "$$p(X, Y) = p(x_0, x_1, y_0, y_1) = p(y_0) \\cdot p(x_0, x_1, y_1 | y_0) = p(y_0) \\cdot p(x_0 | y_0) \\cdot\n",
    "p(x_1, y_1 | x_0, y_0) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | x_0, y_0) \\cdot p(x_1 | x_0, y_0, y_1)\n",
    "= (\\text{в силу условий наши модели}) = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | y_0) \\cdot p(x_1 | y_1) \\Rightarrow$$ <br>\n",
    "Для последовательности длины $n + 1$:<br>\n",
    "$$p(X, Y) = p(x_0 ... x_{n - 1}, y_0 ... y_{n - 1}) \\cdot p(y_n | y_{n - 1}) \\cdot p(x_n | y_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tysPoe5rwC6I"
   },
   "source": [
    "#### Алгоритм Витерби для применения модели\n",
    "\n",
    "\n",
    "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{Y} = \\arg \\max_{Y} p(Y|X) = \\arg \\max_{Y} p(Y, X) $$\n",
    "\n",
    "Пусть $\\normalsize Q_{t,s}$ - самая вероятная последовательность скрытых состояний длины $t$ с окончанием в состоянии $s$. $\\normalsize q_{t, s}$ - вероятность этой последовательности.\n",
    "$$(1)\\: \\normalsize q_{t,s} = \\max_{s'} q_{t - 1, s'} \\cdot p(s | s') \\cdot p(o_t | s)$$\n",
    "$\\normalsize Q_{t,s}$ можно восстановить по argmax-ам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpEXdhOfwC6J"
   },
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:    \n",
    "    def __init__(self):\n",
    "    \n",
    "        pass\n",
    "        \n",
    "    def fit(self, train_tokens_tags_list):\n",
    "        \"\"\"\n",
    "        train_tokens_tags_list: массив предложений пар слово-тег (выборка для train) \n",
    "        \"\"\"\n",
    "        tags = [tag for sent in train_tokens_tags_list\n",
    "                for (word, tag) in sent]\n",
    "        words = [word for sent in train_tokens_tags_list\n",
    "                 for (word, tag) in sent]\n",
    "        \n",
    "        tag_num = pd.Series(nltk.probability.FreqDist(tag for tag in tags)).sort_values(ascending=False)\n",
    "        word_num = pd.Series(nltk.probability.FreqDist(word for word in words)).sort_values(ascending=False)\n",
    "        self.most_popular = pd.Series(nltk.probability.FreqDist(noun for noun in [word for sent in train_tokens_tags_list for (word, tag) in sent if tag_num.index[0] in (word, tag)[1]])).sort_values(ascending=False).index[0]\n",
    "        \n",
    "        self.tags = tag_num.index\n",
    "        self.words = word_num.index\n",
    "        \n",
    "        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n",
    "        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n",
    "        \n",
    "        # Вычисляем матрицу A и B по частотам слов и тегов\n",
    "        \n",
    "        # sent - предложение\n",
    "        # sent[i][0] - i слово в этом предложении, sent[i][1] - i тег в этом предложении\n",
    "        for sent in train_tokens_tags_list:\n",
    "            for i in range(len(sent)):\n",
    "                B.loc[sent[i][0], sent[i][1]] += 1 # текущая i-пара слово-тег (обновите матрицу B аналогично A)\n",
    "                if len(sent) - 1 != i: # для последнего тега нет следующего тега\n",
    "                    A.loc[sent[i][1], sent[i + 1][1]] += 1 # пара тег-тег\n",
    "                \n",
    "        \n",
    "        # переходим к вероятностям\n",
    "        \n",
    "        # нормируем по строке, то есть по всем всевозможным следующим тегам\n",
    "        A = A.divide(A.sum(axis=1), axis=0)\n",
    "        \n",
    "        # нормируем по столбцу, то есть по всем всевозможным текущим словам\n",
    "        B = B / np.sum(B, axis=0)\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def predict(self, test_tokens_list):\n",
    "        \"\"\"\n",
    "        test_tokens_list : массив предложений пар слово-тег (выборка для test)\n",
    "        \"\"\"\n",
    "        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n",
    "        \n",
    "        for i_sent in range(len(test_tokens_list)):\n",
    "            \n",
    "            current_sent = test_tokens_list[i_sent] # текущее предложение\n",
    "            len_sent = len(current_sent) # длина предложения \n",
    "            \n",
    "            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
    "            q[0] = 1 # нулевое состояние (равномерная инициализация по всем s)\n",
    "            back_point = np.zeros(shape=(len_sent + 1, len(self.tags))) # # argmax\n",
    "            \n",
    "            for t in range(len_sent):\n",
    "                \n",
    "                # если мы не встречали такое слово в обучении, то вместо него будет \n",
    "                # самое популярное слово с самым популярным тегом (вопрос 2)\n",
    "                if current_sent[t] not in self.words:\n",
    "                    current_sent[t] = self.most_popular\n",
    "                    \n",
    "                # через max выбираем следующий тег\n",
    "                for i_s in range(len(self.tags)):\n",
    "                    \n",
    "                    s = self.tags[i_s]\n",
    "                    \n",
    "                    # формула (1)\n",
    "                    q[t + 1][i_s] = np.max(q[t] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s])\n",
    "                    \n",
    "                    # argmax формула(1)\n",
    "                    \n",
    "                    # argmax, чтобы восстановить последовательность тегов\n",
    "                    back_point[t + 1][i_s] = (q[t] * self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t],s]).reset_index()[s].idxmax() # индекс \n",
    "                    \n",
    "            back_point = back_point.astype('int')\n",
    "            \n",
    "            # выписываем теги, меняя порядок на реальный\n",
    "            back_tag = deque()\n",
    "            current_tag = np.argmax(q[len_sent])\n",
    "            for t in range(len_sent, 0, -1):\n",
    "                back_tag.appendleft(self.tags[current_tag])\n",
    "                current_tag = back_point[t, current_tag]\n",
    "             \n",
    "            predict_tags[i_sent] = np.array(back_tag)\n",
    "        \n",
    "        \n",
    "        return predict_tags                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0BLgsWkwC6M"
   },
   "source": [
    "Обучите скрытую марковскую модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcSoyUAxwC6M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HiddenMarkovModel at 0x7fa22565ec18>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_model = ..,\n",
    "my_model = HiddenMarkovModel()\n",
    "my_model.fit(train_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FeVNt19kwC6P"
   },
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "- 'He can stay'\n",
    "- 'a cat and a dog'\n",
    "- 'I have a television'\n",
    "- 'My favourite character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMJErf7NwC6Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, array(['NOUN', 'VERB', 'VERB'], dtype='<U4')),\n",
       "             (1, array(['DET', 'NOUN', 'CONJ', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (2, array(['NOUN', 'VERB', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (3, array(['NOUN', 'NOUN', 'NOUN'], dtype='<U4'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [['He', 'can', 'stay'], ['a', 'cat', 'and', 'a', 'dog'], ['I', 'have', 'a', 'television'],\n",
    "         ['My', 'favourite', 'character']]\n",
    "my_model.predict(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suDCwbGMwC6T"
   },
   "source": [
    "### Вопрос 3:\n",
    "* Какой тег вы получили для слова `can`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReHeG3IjwC6U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict([['can']])[0][0]\n",
    "'VERB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObAslurlwC6X"
   },
   "source": [
    "### Вопрос 4:\n",
    "* Какой тег вы получили для слова `favourite`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94crVrrXwC6Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict([['favourite']])[0][0]\n",
    "'NOUN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPC4NZ4HwC6a"
   },
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7aioBc1wC6b"
   },
   "outputs": [],
   "source": [
    "def accuracy_score(model, sents):\n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "\n",
    "    for sent in sents:\n",
    "        tags = [tag for (word, tag) in sent]\n",
    "        words = [word for (word, tag) in sent]\n",
    "\n",
    "        outputs = model.predict([words])[0]\n",
    "#         print(outputs)\n",
    "#         print(tags)\n",
    "#         print([i==j for i,j in zip(outputs, tags)])\n",
    "        true_pred += np.sum([i==j for i,j in zip(outputs, tags)])\n",
    "        num_pred += len(sent)\n",
    "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roesKrPCcMbp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.52007835455436 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(my_model, test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ff_W7J8XwC6e"
   },
   "source": [
    "### Вопрос 5:\n",
    "* Какое качество вы получили(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptvlpc-6wC6f"
   },
   "outputs": [],
   "source": [
    "89.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpAgfZRTwC6h"
   },
   "source": [
    "## DefaultTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b4cPKyiwC6j"
   },
   "source": [
    "### Вопрос 6:\n",
    "* Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pM28MT0gcMb2"
   },
   "outputs": [],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "\n",
    "    #outputs = model.predict([words])[0]\n",
    "\n",
    "    true_pred += np.sum(['NOUN'] * len(words) == tags)\n",
    "    num_pred += len(words)\n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Td-0Pe0vwC6k"
   },
   "source": [
    "Вы можете испоьзовать DefaultTagger(метод tag для предсказания частей речи предложения) или можете преобразовать код выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfZYlMxJwC6m"
   },
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('''your code''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CXKibo_cMcB"
   },
   "outputs": [],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "    \n",
    "    tagged_sent = default_tagger.tag(words)\n",
    "    outputs = [tag for token, tag in tagged_sent]\n",
    "    \n",
    "    true_pred += np.sum(outputs == tags)\n",
    "    num_pred += len(words)\n",
    "    \n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lz7Q3BfbwC6o"
   },
   "source": [
    "## Модель Стенфорда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKYPKJYLwC6p"
   },
   "source": [
    "Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. \n",
    "Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yW-PR54QwC6p",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag.mapping import map_tag\n",
    "\n",
    "# используйте путь до jar и до model\n",
    "jar = './stanford-postagger-2018-10-16/stanford-postagger-3.9.2.jar'\n",
    "model = './stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger'\n",
    "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "\n",
    "# проверим на предложении\n",
    "tagged_sent = stanford_tagger.tag(['I', 'bear', 'a', 'bag'])\n",
    "print('Ответ: ', [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1z8x4vvwC6s"
   },
   "source": [
    "### Вопрос 7:\n",
    "* Какое качество вы получили на модели Стенфорда(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBd3RgqVwC6s"
   },
   "outputs": [],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "    \n",
    "    tagged_sent = stanford_tagger.tag(words)\n",
    "    outputs = [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent]\n",
    "    \n",
    "    true_pred += np.sum(outputs == tags)\n",
    "    num_pred += len(words)\n",
    "    \n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5w1W5hSkcMcV"
   },
   "source": [
    "## BiLSTMTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKrdRnpscMcV"
   },
   "source": [
    "Для того, чтобы успешнее справиться с дальнейшей частью, вам лучше обратиться к семинару 3(Language Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mm1-S3t2cMcW"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GayTl7mUcMcX"
   },
   "source": [
    "Изменим структуру данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnXcI64fxoj4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_data = [list(zip(*sent)) for sent in brown_tagged_sents]\n",
    "print(pos_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpRE3c-3cMcc"
   },
   "source": [
    "До этого мы писали много кода сами, теперь пора эксплуатировать pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvFlzrYnxokE"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "import torchtext\n",
    "\n",
    "# наши поля\n",
    "WORD = Field(lower=True)\n",
    "TAG = Field(unk_token=None) # все токены нам извсетны\n",
    "\n",
    "# создаем примеры\n",
    "examples = []\n",
    "for words, tags in pos_data:\n",
    "    examples.append(torchtext.data.Example.fromlist([list(words), list(tags)], fields=[('words', WORD), ('tags', TAG)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUhTrWCWcMcj"
   },
   "source": [
    "Теперь формируем наш датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGKkbZUIxokO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# кладем примеры в наш датасет\n",
    "dataset = torchtext.data.Dataset(examples, fields=[('words', WORD), ('tags', TAG)])\n",
    "\n",
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T89unpppcMcp"
   },
   "source": [
    "Построим словари. Параметр `min_freq` выберете сами. При построении словаря испольузем только train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZwkwhlrxoka",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WORD.build_vocab('''your code''', min_freq='''your code''')\n",
    "TAG.build_vocab('''your code''')\n",
    "\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(WORD.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TAG.vocab)}\")\n",
    "\n",
    "print(WORD.vocab.itos[::200])\n",
    "print(TAG.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjn07NP-xokl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxgkU4cZcMcz"
   },
   "source": [
    "Посмотрим с насколько большими предложениями мы имеем дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVpMi1_0xoku",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length = map(len, [vars(x)['words'] for x in train_data.examples])\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.title(\"Length distribution in Train data\")\n",
    "plt.hist(list(length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yi28N2RBcMc5"
   },
   "source": [
    "Для обучения `BiLSTM` лучше использовать colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAGSrqWsxok2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2DSWm0UjcMc-"
   },
   "source": [
    "Для более быстрого и устойчивого обучения сгруппируем наши данные по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmwAyhNgxok_"
   },
   "outputs": [],
   "source": [
    "# бьем нашу выборку на батч, не забывая сначала отсортировать выборку по длине\n",
    "def _len_sort_key(x):\n",
    "    return len(x.words)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aTjW00nxolI"
   },
   "outputs": [],
   "source": [
    "# посморим  на количество батчей\n",
    "list(map(len, [train_iterator, valid_iterator, test_iterator]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyLQsizhcMdI"
   },
   "source": [
    "### Модель и её обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-i9oHzcrcMdJ"
   },
   "source": [
    "Инициализируем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff7BLWs_xolS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, dropout, bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "  \n",
    "        self.embeddings = '''your code'''\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.rnn = nn.LSTM('''your code''')\n",
    "        self.tag = nn.Linear((1 + bidirectional) * hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, sent):\n",
    "        \n",
    "        #sent = [sent len, batch size] \n",
    "        \n",
    "        # не забываем применить dropout к embedding\n",
    "        embedded = self.dropout('''your code''')\n",
    "\n",
    "        output, _ = self.rnn(embedded)\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "\n",
    "        prediction = self.tag('''your code''')\n",
    "    \n",
    "        return prediction\n",
    "        \n",
    "# параметры модели\n",
    "INPUT_DIM = len(WORD.vocab)\n",
    "OUTPUT_DIM = len(TAG.vocab)\n",
    "EMB_DIM = '''your code'''\n",
    "HID_DIM = '''your code'''\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = '''your code'''\n",
    "\n",
    "model = LSTMTagger('''your code''').to(device)\n",
    "\n",
    "# инициализируем веса\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJLqq8IHcMdQ"
   },
   "source": [
    "Подсчитаем количество обучаемых параметров нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Auu53Kdxolm"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return '''your code'''\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy_ljMLfcMdX"
   },
   "source": [
    "Наша модель готова, осталось сформировать loss. На семинаре мы искали loss таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxCuuxj8xoms"
   },
   "outputs": [],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "    \n",
    "output = model(x.words)\n",
    "logp = torch.gather(F.log_softmax(output, -1), dim=2, index=x.tags[:,:,None])\n",
    "-logp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocEG3mdOxomz"
   },
   "source": [
    "Сейчас мы не будем выбирать только нужные объекты, а сразу воспользуемся помощью pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCumIFWRxom4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion(output.view(-1, output.shape[-1]), x.tags.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oSBfvf9HcMd9"
   },
   "source": [
    "Погнали обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjD1Y7Rmxolu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PAD_IDX = TAG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "       '''your code'''\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model('''your code''')\n",
    "        \n",
    "        #tags = [sent len, batch size]\n",
    "        #output = [sent len, batch size, output dim]\n",
    "        \n",
    "        output = '''your code'''\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        #tags = [sent len * batch size]\n",
    "        #output = [sent len * batch size, output dim]\n",
    "        \n",
    "        loss = criterion('''your code''')\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping(решение проблемы взрыва граденты), clip - максимальная норма вектора\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            \n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            '''your code'''\n",
    "\n",
    "            output = model('''your code''')\n",
    "\n",
    "            #tags = [sent len, batch size]\n",
    "            #output = [sent len, batch size, output dim]\n",
    "\n",
    "            output = '''your code'''\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            #tags = [sent len * batch size]\n",
    "            #output = [sent len * batch size, output dim]\n",
    "\n",
    "            loss = criterion('''your code''')\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJdXIyTHxol2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = '''your code'''\n",
    "CLIP = '''your code'''\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fr860UPacMeI"
   },
   "source": [
    "### Применение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sDAfAq9xol9"
   },
   "outputs": [],
   "source": [
    "def accuracy_model(model, iterator):\n",
    "    model.eval()\n",
    "    \n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "           '''your code'''\n",
    "\n",
    "            output = model('''your code''')\n",
    "            \n",
    "            #output = [sent len, batch size, output dim]\n",
    "            output = '''your code'''\n",
    "            \n",
    "            #output = [sent len, batch size]\n",
    "            predict_tags = output.cpu().numpy()\n",
    "            true_tags = tags.cpu().numpy()\n",
    "\n",
    "            true_pred += np.sum((true_tags == predict_tags) & (true_tags != PAD_IDX))\n",
    "            num_pred += np.prod(tags.shape)\n",
    "        \n",
    "    return round(true_pred / num_pred * 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2n0H85mxomE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_model(model, test_iterator), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FacTKSPJcMeP"
   },
   "source": [
    "Вы можете улучшить качество, изменяя параметры модели. Но чтобы добиться нужного качества, вам неообходимо взять все выборку, а не только категорию `humor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXqXg0gbcMeR"
   },
   "outputs": [],
   "source": [
    "#brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnpi2R6rcMeU"
   },
   "source": [
    "Вам неоходимо добиться качества не меньше, чем `accuracy = 92 %` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqD1lZuwxomK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL).to(device)\n",
    "best_model.load_state_dict(torch.load('best-val-model.pt'))\n",
    "assert accuracy_model(best_model, test_iterator) >= 92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVfdJM-lcMeZ"
   },
   "source": [
    "Пример решение нашей задачи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3GUbwldxomW"
   },
   "outputs": [],
   "source": [
    "def print_tags(model, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        words, _ = data\n",
    "        example = torch.LongTensor([WORD.vocab.stoi[elem] for elem in words]).unsqueeze(1).to(device)\n",
    "        \n",
    "        output = model(example).argmax(dim=-1).cpu().numpy()\n",
    "        tags = [TAG.vocab.itos[int(elem)] for elem in output]\n",
    "\n",
    "        for token, tag in zip(words, tags):\n",
    "            print(f'{token:15s}{tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mQoHc_EcMed",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_tags(model, pos_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "zMIJDOBmwC6v"
   },
   "source": [
    "## Сравните результаты моделей"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]language_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
