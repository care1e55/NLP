{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде всего необходимо установить и загрузить некоторые необходимые для выполнения задания модули "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/care1e55/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/care1e55/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать датасеты\n",
    "# wget https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "# wget https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "# wget https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'corpus'\n",
    "raw_corpus_path = os.path.join(base_path, 'fanfiction_texts')\n",
    "tokenized_corpus_path = os.path.join(base_path, 'hpac_source')\n",
    "split_corpus_path = os.path.join(base_path, 'hpac_corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на первую строку случайных файлов корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_text_file = random.choice(os.listdir(raw_corpus_path))\n",
    "with open(os.path.join(raw_corpus_path, raw_text_file)) as f:\n",
    "    for line in f.readlines():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disclaimer:  I don't own Harry Potter or the wonderful magical world in which he lives. I'm just having fun. Note:  THANKS to my betas on this story: kazfeist and eilonwy! This story was a lot of fun, I hope you like it! ooo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_text_file = random.choice(os.listdir(tokenized_corpus_path))\n",
    "with open(os.path.join(raw_corpus_path, raw_text_file)) as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Эксплоративный анализ\n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет частот всех попдающихся слов с помощью акумулирующего Counter. Потом top 1000 можно будет получить вызвав метод most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36225/36225 [19:22<00:00, 31.16it/s]\n"
     ]
    }
   ],
   "source": [
    "top_1000 = Counter()\n",
    "for raw_text_file in tqdm(os.listdir(tokenized_corpus_path)):\n",
    "    with open(os.path.join(tokenized_corpus_path, raw_text_file)) as f:\n",
    "        for line in f:\n",
    "            top_1000 += Counter(line.split())\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_1000.pckl\", 'wb') as file:\n",
    "    pickle.dump(top_1000, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_1000.pckl\", 'rb') as file:\n",
    "    top_1000 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 613880/613880 [00:44<00:00, 13769.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# filter stopwords and word with punctuation\n",
    "top_1000_filtered = { \n",
    "    word: count for word, count in tqdm(top_1000.items()) \n",
    "    if word not in stopwords.words(\"english\")\n",
    "    and not any(punct in word for punct in string.punctuation)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод 1000 слов займет слишком много места. Пока что выведем 10, а позже 1000 понадобится для визуализации эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harry', 3991017),\n",
       " ('said', 2262072),\n",
       " ('would', 1903185),\n",
       " ('hermione', 1826879),\n",
       " ('could', 1687864),\n",
       " ('back', 1396452),\n",
       " ('draco', 1386180),\n",
       " ('one', 1376314),\n",
       " ('like', 1256561),\n",
       " ('know', 1179021)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counter(top_1000_filtered).most_common(1000)\n",
    "Counter(top_1000_filtered).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понадобятся функции для фильтрации и итератор возвращающий текущее слово и предыдущее. Вторая функциия нужна что бы искать пары слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biwords(words):\n",
    "    for i, word in enumerate(words, 1):\n",
    "        try:\n",
    "            yield word, words[i]\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords_and_punkt(tokens):\n",
    "    return list(filter(\n",
    "        lambda word: \n",
    "            word.lower() not in stopwords.words(\"english\") \n",
    "            and not any(punct in word for punct in string.punctuation)\n",
    "        , tokens\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем все слова начинающиеся с большой буквы, пары таких слов и со словом professor перед ним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "full_names = []\n",
    "professor_names = []\n",
    "\n",
    "for raw_text_file in tqdm(os.listdir(raw_corpus_path)):\n",
    "    with open(os.path.join(raw_corpus_path, raw_text_file)) as f:\n",
    "        for line in f:\n",
    "            tokens = nltk.word_tokenize(line)\n",
    "            for token_pair in biwords(tokens):\n",
    "                if token_pair[0].istitle():\n",
    "                    names.append(token_pair[0])\n",
    "                    if token_pair[1].istitle(): full_names.append(' '.join(token_pair))\n",
    "                    if token_pair[0].lower()=='professor' and token_pair[1].istitle(): \n",
    "                        professor_names.append(' '.join(token_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним\n",
    "# with open(\"names.pckl\", 'wb') as file:\n",
    "#     pickle.dump(names, file)\n",
    "# with open(\"full_names.pckl\", 'wb') as file:\n",
    "#     pickle.dump(full_names, file)\n",
    "# with open(\"professor_names.pckl\", 'wb') as file:\n",
    "#     pickle.dump(professor_names, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списки попали не только имена, но и нарицательные и начала преложений, поэтому можно найти имена которые протегирует NER модель как PERSON. Предварительно необходимо ее скачать, а также, поскольку это .jar необходима установленная java (тестировалось на openjdk 8). Здесь она лежит в корне вместе в ноутбуком. Полностью список может не уместиться в памяти, поэтому делаем обработку побатчево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:13<00:00,  5.22s/it]\n"
     ]
    }
   ],
   "source": [
    "tagged_fn = []\n",
    "batch_size = 100000\n",
    "flattened_fn = [j for i in Counter(full_names).keys() for j in i.split()]\n",
    "for i in tqdm(range(0, len(flattened_fn), batch_size)):\n",
    "    tagged_fn += st.tag(flattened_fn[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "tagged_pn = []\n",
    "batch_size = 100000\n",
    "flattened_pn = [j for i in Counter(professor_names).keys() for j in i.split()]\n",
    "for i in tqdm(range(0, len(flattened_pn), batch_size)):\n",
    "    tagged_pn += st.tag(flattened_pn[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282329/282329 [00:00<00:00, 2986988.46it/s]\n",
      "1311337it [00:00, 2302662.28it/s]\n",
      "7177it [00:00, 1559150.56it/s]\n"
     ]
    }
   ],
   "source": [
    "tagged_names = []\n",
    "tagged_full_names = []\n",
    "tagged_professor_names = []\n",
    "\n",
    "counter_tagged_names = Counter()\n",
    "counter_tagged_full_names = Counter()\n",
    "counter_tagged_professor_names = Counter()\n",
    "\n",
    "counter_names = Counter(names)\n",
    "counter_full_names = Counter(full_names)\n",
    "counter_professor_names = Counter(professor_names)\n",
    "\n",
    "for tag in tqdm(st.tag(counter_names.keys())):\n",
    "    if tag[1] == 'PERSON': counter_tagged_names[tag[0]] = counter_names[tag[0]]\n",
    "for tags in tqdm(biwords(tagged_fn)):\n",
    "    if tags[0][1]=='PERSON' and tags[1][1]=='PERSON':\n",
    "        counter_key = ' '.join([tags[0][0], tags[1][0]])\n",
    "        counter_tagged_full_names[counter_key] = counter_full_names[counter_key]\n",
    "for tags in tqdm(biwords(tagged_pn)):\n",
    "    if tags[0][0].lower()=='professor' and tags[1][1]=='PERSON':\n",
    "        counter_key = ' '.join([tags[0][0], tags[1][0]])\n",
    "        counter_tagged_professor_names[counter_key] = counter_professor_names[counter_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry', 3881517),\n",
       " ('Draco', 1353411),\n",
       " ('Ron', 881149),\n",
       " ('Ginny', 620418),\n",
       " ('Snape', 581473),\n",
       " ('Malfoy', 472014),\n",
       " ('Dumbledore', 459590),\n",
       " ('Remus', 420104),\n",
       " ('Voldemort', 383796),\n",
       " ('Neville', 216927)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tagged_names.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harry Potter', 124825),\n",
       " ('Draco Malfoy', 47237),\n",
       " ('Professor Snape', 42366),\n",
       " ('Miss Granger', 35790),\n",
       " ('Severus Snape', 30498),\n",
       " ('Hermione Granger', 30052),\n",
       " ('James Potter', 27171),\n",
       " ('Sirius Black', 26291),\n",
       " ('Lucius Malfoy', 23940),\n",
       " ('Albus Dumbledore', 20988)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tagged_full_names.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Professor Snape', 42366),\n",
       " ('Professor Dumbledore', 22112),\n",
       " ('Professor Flitwick', 8995),\n",
       " ('Professor Trelawney', 2966),\n",
       " ('Professor Umbridge', 2745),\n",
       " ('Professor Longbottom', 2296),\n",
       " ('Professor Binns', 2023),\n",
       " ('Professor Quirrell', 1666),\n",
       " ('Professor Potter', 1454),\n",
       " ('Professor Lockhart', 1363)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tagged_professor_names.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Модели представления слов\n",
    "1. Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import word2vec\n",
    "from gensim.utils import tokenize\n",
    "from gensim import utils\n",
    "from pymystem3 import Mystem\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции для фильтрации, лемматизации и определения итератора по строкам всех файлов чтобы не загружать корпус в память. К сожалению фильтрация и лематизация делает обучение слишком долгим, поэтому пока обучаем эмбединги на необработанном корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Mystem()\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemm_word(word):\n",
    "    return lemmatizer.lemmatize(word)[0]\n",
    "    \n",
    "def lemm(words):\n",
    "    return [lemm_word(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_punkt(tokens):\n",
    "    return [token for token in tokens if not any(punct in word for punct in string.punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullCorpusIterator():\n",
    "    def __iter__(self):\n",
    "        for raw_text_file in os.listdir(tokenized_corpus_path):\n",
    "            with open(os.path.join(tokenized_corpus_path, raw_text_file)) as f:\n",
    "                for line in f:\n",
    "                    yield line.split()\n",
    "#                     yield lemm(filter_stopwords_and_punkt(tokenize(line))) # unfortunatly too slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для fasttext, но дальше будет обучен и использоваться Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-21 21:36:06,260 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "# embedder_model = FastText(size=100, min_count=1)\n",
    "# epochs = 10\n",
    "# embedder_model.build_vocab(sentences=FullCorpusIterator())\n",
    "# embedder_model.train(\n",
    "#     sentences=FullCorpusIterator(), \n",
    "#     epochs=epochs,\n",
    "#     total_examples=embedder_model.corpus_count, \n",
    "#     total_words=embedder_model.corpus_total_words,\n",
    "# )\n",
    "# with open(\"embedder_model.pckl\", 'wb') as file:\n",
    "#     pickle.dump(embedder_model, file)\n",
    "# embedder_model.wv.most_similar(\"strange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.Word2Vec(\n",
    "    sentences=FullCorpusIterator(), \n",
    "    workers=8, \n",
    "    size=300, \n",
    "    min_count=10, \n",
    "    window=10, \n",
    "    sample=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-21 23:38:10,799 : INFO : saving Word2Vec object under w2vmodel.model, separately None\n",
      "2021-02-21 23:38:10,801 : INFO : storing np array 'vectors' to w2vmodel.model.wv.vectors.npy\n",
      "2021-02-21 23:38:10,861 : INFO : not storing attribute vectors_norm\n",
      "2021-02-21 23:38:10,862 : INFO : storing np array 'syn1neg' to w2vmodel.model.trainables.syn1neg.npy\n",
      "2021-02-21 23:38:10,915 : INFO : not storing attribute cum_table\n",
      "2021-02-21 23:38:11,026 : INFO : saved w2vmodel.model\n"
     ]
    }
   ],
   "source": [
    "# Сохранение\n",
    "# word2vec_model.save(\"w2vmodel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-25 00:55:24,017 : INFO : loading Word2Vec object from w2vmodel.model\n",
      "2021-02-25 00:55:24,215 : INFO : loading wv recursively from w2vmodel.model.wv.* with mmap=None\n",
      "2021-02-25 00:55:24,215 : INFO : loading vectors from w2vmodel.model.wv.vectors.npy with mmap=None\n",
      "2021-02-25 00:55:24,270 : INFO : setting ignored attribute vectors_norm to None\n",
      "2021-02-25 00:55:24,270 : INFO : loading vocabulary recursively from w2vmodel.model.vocabulary.* with mmap=None\n",
      "2021-02-25 00:55:24,271 : INFO : loading trainables recursively from w2vmodel.model.trainables.* with mmap=None\n",
      "2021-02-25 00:55:24,271 : INFO : loading syn1neg from w2vmodel.model.trainables.syn1neg.npy with mmap=None\n",
      "2021-02-25 00:55:24,323 : INFO : setting ignored attribute cum_table to None\n",
      "2021-02-25 00:55:24,324 : INFO : loaded w2vmodel.model\n"
     ]
    }
   ],
   "source": [
    "# Загрузка\n",
    "# word2vec_model = word2vec.Word2Vec.load(\"w2vmodel.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели.\n",
    "Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть как с помощью эмбедингов работает поиск синонимов, ассоциаций и лишних слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-22 01:34:25,521 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('snape', 0.5841378569602966)]\n",
      "[('headmaster', 0.5601098537445068)]\n",
      "[('severus', 0.6625256538391113), ('aberforth', 0.6533681154251099), ('dumbledore', 0.6430376768112183)]\n",
      "leviosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/care1e55/.local/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model.wv.most_similar(positive=[\"harry\", \"potter\"], negative=[\"ron\"], topn=1))\n",
    "print(word2vec_model.wv.most_similar(positive=[\"albus\", \"dumbledore\"], negative=[\"minerva\"], topn=1))\n",
    "print(word2vec_model.wv.most_similar(\"albus\", topn=3))\n",
    "print(word2vec_model.wv.doesnt_match(\"albus harry draco leviosa\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация производится с помощью быстрой реализации t-SNE на CUDA. Преварительно ее следует установить.\n",
    "Визуализируем эмбединги для подсчитанных предварительно топ 1000 слов. Визуализация с помошью bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-25 00:55:21,743 : INFO : Loading faiss with AVX2 support.\n",
      "2021-02-25 00:55:21,744 : INFO : Loading faiss.\n"
     ]
    }
   ],
   "source": [
    "from tsnecuda import TSNE\n",
    "import faiss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 702681.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# get embedded words\n",
    "embeded = []\n",
    "labeles = []\n",
    "# for word in tqdm(word2vec_model.wv.vocab.keys()):\n",
    "for word in tqdm([i[0] for i in Counter(top_1000_filtered).most_common(1000)]):\n",
    "    try:\n",
    "        embeded.append(word2vec_model.wv.get_vector(word))\n",
    "        labeles.append(word)\n",
    "    except:\n",
    "        pass\n",
    "# print(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train t-sne\n",
    "tsne = TSNE(n_components=2, verbose=5)\n",
    "word_vectors_tsne = tsne.fit_transform(np.array(embeded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отнормируем и выполним преобразование\n",
    "ss = StandardScaler().fit(word_vectors_tsne)\n",
    "word_vectors_tsne = ss.transform(word_vectors_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"3277333d-0147-4d29-bd36-3d08db71cbaa\" data-root-id=\"1003\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"546293e3-367f-4d48-85e4-38e48d9edbe2\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1012\"}],\"center\":[{\"id\":\"1015\"},{\"id\":\"1019\"}],\"left\":[{\"id\":\"1016\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1037\"}],\"title\":{\"id\":\"1041\"},\"toolbar\":{\"id\":\"1027\"},\"x_range\":{\"id\":\"1004\"},\"x_scale\":{\"id\":\"1008\"},\"y_range\":{\"id\":\"1006\"},\"y_scale\":{\"id\":\"1010\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\"},\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"HelpTool\"},{\"attributes\":{\"axis\":{\"id\":\"1012\"},\"ticker\":null},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1004\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"dimension\":1,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1021\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1039\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"PanTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1026\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1036\",\"type\":\"Scatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\"},\"glyph\":{\"id\":\"1035\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1036\"},\"selection_glyph\":null,\"view\":{\"id\":\"1038\"}},\"id\":\"1037\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1002\"}},\"id\":\"1038\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1039\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{\"text\":\"\"},\"id\":\"1041\",\"type\":\"Title\"},{\"attributes\":{\"data\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"token\":[\"harry\",\"said\",\"would\",\"hermione\",\"could\",\"back\",\"draco\",\"one\",\"like\",\"know\",\"eyes\",\"time\",\"ron\",\"looked\",\"get\",\"asked\",\"well\",\"even\",\"around\",\"see\",\"head\",\"going\",\"think\",\"still\",\"go\",\"severus\",\"face\",\"way\",\"room\",\"ginny\",\"hand\",\"sirius\",\"something\",\"want\",\"thought\",\"potter\",\"right\",\"snape\",\"away\",\"much\",\"look\",\"two\",\"never\",\"really\",\"knew\",\"first\",\"let\",\"made\",\"good\",\"malfoy\",\"little\",\"wand\",\"felt\",\"dumbledore\",\"turned\",\"james\",\"come\",\"got\",\"make\",\"took\",\"remus\",\"lily\",\"though\",\"sure\",\"say\",\"door\",\"tell\",\"take\",\"us\",\"looking\",\"dark\",\"voice\",\"voldemort\",\"last\",\"long\",\"told\",\"need\",\"left\",\"yes\",\"man\",\"wanted\",\"anything\",\"next\",\"oh\",\"came\",\"nodded\",\"love\",\"moment\",\"people\",\"saw\",\"another\",\"things\",\"went\",\"hands\",\"ca\",\"help\",\"day\",\"enough\",\"death\",\"smiled\",\"professor\",\"year\",\"mind\",\"nothing\",\"found\",\"ever\",\"boy\",\"hair\",\"always\",\"find\",\"bit\",\"seemed\",\"behind\",\"hogwarts\",\"thing\",\"bed\",\"trying\",\"feel\",\"started\",\"put\",\"since\",\"life\",\"house\",\"night\",\"heard\",\"black\",\"without\",\"smile\",\"better\",\"years\",\"gave\",\"magic\",\"might\",\"side\",\"weasley\",\"everyone\",\"father\",\"sat\",\"began\",\"someone\",\"almost\",\"walked\",\"done\",\"finally\",\"already\",\"tried\",\"place\",\"every\",\"stood\",\"everything\",\"friends\",\"three\",\"lord\",\"front\",\"pulled\",\"small\",\"also\",\"quickly\",\"course\",\"keep\",\"girl\",\"body\",\"best\",\"towards\",\"else\",\"arms\",\"neville\",\"table\",\"give\",\"mean\",\"work\",\"family\",\"sorry\",\"albus\",\"please\",\"end\",\"many\",\"world\",\"school\",\"mother\",\"great\",\"lucius\",\"old\",\"together\",\"new\",\"quite\",\"stop\",\"happened\",\"leave\",\"replied\",\"maybe\",\"mouth\",\"open\",\"yet\",\"must\",\"soon\",\"later\",\"floor\",\"getting\",\"able\",\"words\",\"arm\",\"name\",\"lips\",\"friend\",\"least\",\"hard\",\"feeling\",\"actually\",\"suddenly\",\"anyone\",\"seen\",\"slowly\",\"sighed\",\"luna\",\"talk\",\"spell\",\"shook\",\"making\",\"gone\",\"rather\",\"george\",\"believe\",\"probably\",\"held\",\"home\",\"far\",\"light\",\"used\",\"inside\",\"granger\",\"wo\",\"second\",\"opened\",\"rest\",\"taking\",\"fred\",\"stopped\",\"hear\",\"idea\",\"whispered\",\"rose\",\"coming\",\"across\",\"thank\",\"try\",\"breath\",\"care\",\"slightly\",\"tom\",\"parents\",\"yeah\",\"students\",\"called\",\"needed\",\"ask\",\"laughed\",\"close\",\"may\",\"watched\",\"use\",\"continued\",\"slytherin\",\"sitting\",\"gryffindor\",\"part\",\"heart\",\"morning\",\"blood\",\"feet\",\"happy\",\"lot\",\"pain\",\"book\",\"muggle\",\"remember\",\"okay\",\"hall\",\"fact\",\"past\",\"stared\",\"reached\",\"however\",\"fine\",\"chapter\",\"ministry\",\"thinking\",\"wrong\",\"along\",\"onto\",\"hope\",\"alone\",\"shoulder\",\"set\",\"read\",\"moved\",\"wizard\",\"bad\",\"standing\",\"either\",\"red\",\"chest\",\"decided\",\"fell\",\"talking\",\"dead\",\"minutes\",\"stay\",\"ran\",\"hurt\",\"understand\",\"young\",\"potion\",\"mcgonagall\",\"fingers\",\"instead\",\"caught\",\"person\",\"kill\",\"days\",\"woman\",\"miss\",\"potions\",\"point\",\"others\",\"air\",\"tears\",\"ready\",\"kiss\",\"ground\",\"tonks\",\"kept\",\"matter\",\"taken\",\"son\",\"times\",\"wait\",\"order\",\"forward\",\"deep\",\"closed\",\"noticed\",\"eaters\",\"curse\",\"story\",\"reason\",\"lost\",\"kind\",\"raised\",\"full\",\"sound\",\"sleep\",\"magical\",\"thanks\",\"move\",\"blaise\",\"different\",\"wall\",\"whole\",\"office\",\"bellatrix\",\"several\",\"question\",\"followed\",\"start\",\"half\",\"turn\",\"word\",\"perhaps\",\"anyway\",\"large\",\"outside\",\"answer\",\"holding\",\"class\",\"attention\",\"answered\",\"chair\",\"hit\",\"completely\",\"lupin\",\"exactly\",\"quietly\",\"scorpius\",\"waiting\",\"cold\",\"immediately\",\"mum\",\"ago\",\"minerva\",\"spoke\",\"robes\",\"saying\",\"eye\",\"longer\",\"today\",\"leaving\",\"watching\",\"stepped\",\"true\",\"green\",\"seeing\",\"hold\",\"staring\",\"child\",\"surprised\",\"pansy\",\"given\",\"master\",\"silence\",\"dad\",\"nearly\",\"turning\",\"softly\",\"nice\",\"neck\",\"headmaster\",\"finished\",\"fire\",\"meant\",\"brought\",\"closer\",\"simply\",\"witch\",\"grabbed\",\"four\",\"show\",\"grinned\",\"hell\",\"war\",\"managed\",\"realized\",\"charm\",\"says\",\"call\",\"change\",\"bloody\",\"looks\",\"narcissa\",\"top\",\"running\",\"children\",\"quidditch\",\"kissed\",\"killed\",\"chance\",\"speak\",\"common\",\"brother\",\"shut\",\"skin\",\"week\",\"sent\",\"alright\",\"added\",\"pointed\",\"castle\",\"met\",\"rolled\",\"known\",\"expression\",\"boys\",\"molly\",\"supposed\",\"returned\",\"walking\",\"muttered\",\"whatever\",\"run\",\"fight\",\"knowing\",\"hours\",\"appeared\",\"leaned\",\"cast\",\"girls\",\"giving\",\"less\",\"happen\",\"upon\",\"books\",\"thoughts\",\"shrugged\",\"pretty\",\"water\",\"sort\",\"guess\",\"spells\",\"throat\",\"gently\",\"letter\",\"worry\",\"real\",\"pushed\",\"loved\",\"big\",\"stairs\",\"hagrid\",\"possible\",\"surprise\",\"couple\",\"glanced\",\"white\",\"meet\",\"seem\",\"passed\",\"fear\",\"bill\",\"five\",\"beside\",\"become\",\"desk\",\"watch\",\"sit\",\"smiling\",\"stand\",\"power\",\"placed\",\"dinner\",\"although\",\"sense\",\"toward\",\"corner\",\"merlin\",\"late\",\"safe\",\"die\",\"sir\",\"stupid\",\"bring\",\"walk\",\"wizards\",\"anymore\",\"soft\",\"kitchen\",\"snapped\",\"agreed\",\"eater\",\"wondered\",\"baby\",\"knows\",\"wish\",\"quiet\",\"telling\",\"break\",\"changed\",\"group\",\"peter\",\"laugh\",\"window\",\"pulling\",\"moving\",\"return\",\"charlie\",\"plan\",\"angry\",\"case\",\"short\",\"trust\",\"explained\",\"shot\",\"free\",\"dropped\",\"shoulders\",\"near\",\"sister\",\"gaze\",\"barely\",\"sight\",\"reading\",\"live\",\"beautiful\",\"especially\",\"died\",\"within\",\"cut\",\"figure\",\"christmas\",\"shaking\",\"tonight\",\"working\",\"worried\",\"spent\",\"clear\",\"months\",\"seat\",\"entire\",\"blue\",\"legs\",\"shouted\",\"dear\",\"memory\",\"frowned\",\"living\",\"stomach\",\"fall\",\"conversation\",\"straight\",\"allowed\",\"control\",\"wizarding\",\"stone\",\"remembered\",\"tone\",\"afraid\",\"fun\",\"form\",\"picked\",\"anger\",\"glad\",\"broke\",\"touch\",\"entered\",\"hour\",\"silent\",\"quick\",\"grin\",\"truth\",\"cried\",\"meeting\",\"nose\",\"laughing\",\"hey\",\"play\",\"smirked\",\"step\",\"certain\",\"important\",\"became\",\"weeks\",\"filled\",\"none\",\"auror\",\"warm\",\"team\",\"using\",\"food\",\"percy\",\"older\",\"empty\",\"fleur\",\"threw\",\"hate\",\"expected\",\"cheek\",\"yelled\",\"worse\",\"breakfast\",\"problem\",\"ones\",\"clearly\",\"teddy\",\"cloak\",\"memories\",\"perfect\",\"waited\",\"obviously\",\"shock\",\"liked\",\"arrived\",\"alive\",\"sometimes\",\"certainly\",\"riddle\",\"wife\",\"carefully\",\"note\",\"despite\",\"summer\",\"gotten\",\"information\",\"daphne\",\"job\",\"forced\",\"madam\",\"loud\",\"except\",\"ten\",\"wrapped\",\"tomorrow\",\"clothes\",\"glass\",\"deal\",\"library\",\"strong\",\"calm\",\"strange\",\"tea\",\"worked\",\"trouble\",\"confused\",\"battle\",\"ear\",\"evening\",\"owl\",\"mine\",\"easy\",\"normal\",\"wide\",\"minute\",\"seems\",\"parchment\",\"lay\",\"makes\",\"paused\",\"twins\",\"apparently\",\"daughter\",\"middle\",\"suppose\",\"moments\",\"tired\",\"high\",\"broom\",\"notice\",\"somehow\",\"led\",\"promise\",\"usual\",\"secret\",\"lying\",\"cup\",\"broken\",\"piece\",\"chuckled\",\"arthur\",\"tongue\",\"sounded\",\"men\",\"line\",\"questions\",\"pale\",\"means\",\"doubt\",\"muggles\",\"save\",\"attack\",\"wonder\",\"helped\",\"familiar\",\"explain\",\"finger\",\"bella\",\"aurors\",\"gasped\",\"uncle\",\"game\",\"hissed\",\"jumped\",\"minister\",\"situation\",\"charms\",\"bright\",\"pressed\",\"hospital\",\"mate\",\"whether\",\"position\",\"lifted\",\"glared\",\"manor\",\"moody\",\"headed\",\"seconds\",\"shall\",\"catch\",\"wants\",\"often\",\"fast\",\"asking\",\"dobby\",\"teeth\",\"early\",\"third\",\"asleep\",\"pomfrey\",\"listen\",\"wearing\",\"neither\",\"kingsley\",\"bag\",\"following\",\"letting\",\"sigh\",\"besides\",\"screamed\",\"truly\",\"forget\",\"write\",\"covered\",\"pull\",\"mark\",\"follow\",\"beginning\",\"hoped\",\"elf\",\"keeping\",\"shirt\",\"fighting\",\"student\",\"flew\",\"playing\",\"likely\",\"wondering\",\"eyebrow\",\"guys\",\"direction\",\"easily\",\"usually\",\"learn\",\"hated\",\"ended\",\"crying\",\"starting\",\"lip\",\"somewhere\",\"enjoy\",\"future\",\"husband\",\"edge\",\"eat\",\"flying\",\"azkaban\",\"ah\",\"soul\",\"offered\",\"cheeks\",\"hoping\",\"cry\",\"damn\",\"falling\",\"earlier\",\"tightly\",\"knees\",\"send\",\"shocked\",\"powerful\",\"train\",\"al\",\"serious\",\"money\",\"missed\",\"pair\",\"drink\",\"disappeared\",\"silver\",\"choice\",\"speaking\",\"hot\",\"pocket\",\"hide\",\"expect\",\"age\",\"brown\",\"aware\",\"ravenclaw\",\"definitely\",\"low\",\"spot\",\"eventually\",\"wake\",\"putting\",\"hug\",\"bedroom\",\"forest\",\"ears\",\"killing\",\"mad\",\"aunt\",\"single\",\"simple\",\"god\",\"mirror\",\"waved\",\"scared\",\"laughter\",\"dress\",\"six\",\"present\",\"continue\",\"admit\",\"sounds\",\"join\",\"exclaimed\",\"handed\",\"paper\",\"feelings\",\"blinked\",\"corridor\",\"breathing\",\"slipped\",\"check\",\"showed\",\"relief\",\"forehead\",\"force\",\"sleeping\",\"doors\",\"smirk\",\"younger\",\"box\",\"final\",\"wands\",\"news\",\"murmured\",\"writing\",\"protect\",\"causing\",\"ok\",\"indeed\",\"bathroom\",\"kissing\",\"ball\",\"steps\",\"wards\",\"dangerous\",\"seamus\",\"dean\",\"lunch\",\"glance\",\"alley\",\"obvious\",\"entrance\",\"sudden\",\"stayed\",\"business\",\"apart\",\"evil\",\"married\",\"cedric\",\"busy\",\"visit\",\"touched\",\"honestly\",\"needs\",\"difficult\",\"ring\",\"party\",\"imagine\",\"drew\",\"fault\",\"number\",\"stuff\",\"burst\",\"fuck\",\"dream\",\"leaning\",\"walls\",\"aside\",\"groaned\",\"crowd\",\"slytherins\",\"interrupted\",\"couch\",\"silently\",\"darkness\",\"remained\",\"learned\",\"tower\",\"hello\",\"stated\",\"foot\",\"snake\",\"dragon\",\"odd\",\"mr\",\"teacher\",\"ahead\",\"growled\",\"wanting\",\"lavender\",\"spend\",\"allow\",\"stuck\",\"match\",\"werewolf\",\"lose\",\"date\",\"finish\",\"points\",\"human\",\"grew\",\"blonde\",\"realised\",\"act\",\"hiding\",\"relationship\",\"response\",\"regulus\",\"caused\",\"umbridge\",\"unless\",\"shop\",\"tight\",\"huge\",\"joined\",\"crossed\",\"talked\",\"comes\",\"wing\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]}},\"selected\":{\"id\":\"1049\"},\"selection_policy\":{\"id\":\"1048\"}},\"id\":\"1002\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1026\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"Selection\"},{\"attributes\":{\"formatter\":{\"id\":\"1045\"},\"ticker\":{\"id\":\"1013\"}},\"id\":\"1012\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"546293e3-367f-4d48-85e4-38e48d9edbe2\",\"root_ids\":[\"1003\"],\"roots\":{\"1003\":\"3277333d-0147-4d29-bd36-3d08db71cbaa\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1003"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting.figure.Figure\">Figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'1003', <span id=\"1096\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">align&nbsp;=&nbsp;'start',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_ratio&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;'#ffffff',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[LinearAxis(id='1012', ...)],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;'#ffffff',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">center&nbsp;=&nbsp;[Grid(id='1015', ...), Grid(id='1019', ...)],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_height&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_width&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='1016', ...)],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">margin&nbsp;=&nbsp;(0, 0, 0, 0),</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_height&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_width&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_height&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_width&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;'#e5e5e5',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;1,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_height&nbsp;=&nbsp;400,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_width&nbsp;=&nbsp;600,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[GlyphRenderer(id='1037', ...)],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">reset_policy&nbsp;=&nbsp;'standard',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='1041', ...),</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='1027', ...),</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None,</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='1004', ...),</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='1008', ...),</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='1006', ...),</div></div><div class=\"1095\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='1010', ...))</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"1096\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"1095\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "Figure(id='1003', ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    if isinstance(color, str): color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig\n",
    "\n",
    "draw_vectors(word_vectors_tsne[:, 0], word_vectors_tsne[:, 1], token=labeles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно кластеры, например по частям речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Используйте fastText в качестве baseline-классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext работает с файлом в специальном тестовом формате с __label__ перед целевой переменной, поэтому требуется предобработать датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for file_path in os.listdir(split_corpus_path):\n",
    "    datasets[file_path.split('_')[1]] = pd.read_csv(\n",
    "        os.path.join(split_corpus_path, file_path), sep='\\t', header=None\n",
    "    )\n",
    "    datasets[file_path.split('_')[1]].columns=['location', 'target', 'source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev\n",
      "7605\n",
      "          location   target                                             source\n",
      "0  10873161.0.5925  PROTEGO  could do . kingsley vanished the chair that ro...\n",
      "training\n",
      "60980\n",
      "        location      target  \\\n",
      "0  7642954.0.676  RIDDIKULUS   \n",
      "\n",
      "                                              source  \n",
      "0  were staring at her . she was up next to face ...  \n",
      "test\n",
      "7679\n",
      "         location   target                                             source\n",
      "0  12060772.0.457  STUPEFY  now , his eyes wide and full of apologies he h...\n"
     ]
    }
   ],
   "source": [
    "for key, value in datasets.items():\n",
    "    print(key)\n",
    "    print(len(value))\n",
    "    print(value.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_fasttext(datasets):\n",
    "    with open('data.train.txt', 'w+') as outfile:\n",
    "        for i in range(len(datasets['training'])):\n",
    "            outfile.write('__label__' + datasets['training']['target'][i] + ' '+ datasets['training']['source'][i] + '\\n')\n",
    "\n",
    "    with open('test.txt', 'w+') as outfile:\n",
    "        for i in range(len(datasets['test'])):\n",
    "            outfile.write('__label__' + datasets['test']['target'][i] + ' '+ datasets['test']['source'][i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_for_fasttext(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор на сыром датасете (с пунктцацией и стоп-словами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = fasttext.train_supervised('data.train.txt')\n",
    "result = classifier.test('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.23271259278551895\n",
      "R@1: 0.23271259278551895\n",
      "Number of examples: 7679\n"
     ]
    }
   ],
   "source": [
    "print('P@1:', result[1])\n",
    "print('R@1:', result[2])\n",
    "print('Number of examples:', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если предварительно пофильтровать стоп-слова и пункутацию, видно что качество классификации немного улучшается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['training']['source'] = datasets['training']['source'].str.split().apply(filter_stopwords_and_punkt)\n",
    "datasets['training']['source'] = datasets['training']['source'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним\n",
    "# with open('train_filtered.pkl', 'wb') as f:\n",
    "#     pickle.dump(datasets['training'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перед вызовом функции требуется удалить предыдущие датасеты вручную\n",
    "prepare_for_fasttext(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = fasttext.train_supervised('data.train.txt')\n",
    "result = classifier.test('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.27477536137517905\n",
      "R@1: 0.27477536137517905\n",
      "Number of examples: 7679\n"
     ]
    }
   ],
   "source": [
    "print('P@1:', result[1])\n",
    "print('R@1:', result[2])\n",
    "print('Number of examples:', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматицзация не дает прироста качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['training']['source'] = datasets['training']['source'].str.split().apply(lemm)\n",
    "datasets['training']['source'] = datasets['training']['source'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перед вызовом функции требуется удалить предыдущие датасеты вручную\n",
    "prepare_for_fasttext(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = fasttext.train_supervised('data.train.txt')\n",
    "result = classifier.test('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.27295220731866127\n",
      "R@1: 0.27295220731866127\n",
      "Number of examples: 7679\n"
     ]
    }
   ],
   "source": [
    "print('P@1:', result[1])\n",
    "print('R@1:', result[2])\n",
    "print('Number of examples:', result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Используйте сверточные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import spacy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим датасеты предварительно пофильтровав стоп-слова и пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in datasets.items(): \n",
    "    value['source'] = value['source'].str.split().apply(filter_stopwords_and_punkt)\n",
    "    value['source'] = value['source'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in datasets.items():\n",
    "    value.to_csv(key+'_fitered', sep=\"\\t\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus/hpac_corpus/hpac_dev_128.tsv\n",
      "corpus/hpac_corpus/hpac_training_128.tsv\n",
      "corpus/hpac_corpus/hpac_test_128.tsv\n"
     ]
    }
   ],
   "source": [
    "for file_path in os.listdir(split_corpus_path):\n",
    "    print(os.path.join(split_corpus_path, file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения используется немного модифицированный код с семинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = data.Field(tokenize='spacy')\n",
    "TARGET = data.LabelField()\n",
    "\n",
    "fields = [\n",
    "    (None, None),\n",
    "    ('target', TARGET),\n",
    "    ('source', SOURCE)\n",
    "]\n",
    "\n",
    "train, valid, test = data.TabularDataset.splits(\n",
    "    path = \"\",\n",
    "    train = 'training_fitered',\n",
    "    validation = 'dev_fitered',\n",
    "    test = 'test_fitered',\n",
    "    format = 'tsv',\n",
    "    fields = fields,\n",
    "    skip_header = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета multilabel accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def categorical_accuracy(preds, y):\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop почти без изменений взят из семинара - поправлены размерности и названия полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0 \n",
    "    model.train()\n",
    "    for batch in tqdm(iterator, total=math.ceil(len(train)/BATCH_SIZE)):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.source.cuda())\n",
    "        loss = criterion(predictions, batch.target.cuda())\n",
    "        acc = categorical_accuracy(predictions.detach(), batch.target.detach().cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss\n",
    "        epoch_acc += acc\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_func(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.source.cuda())\n",
    "            loss = criterion(predictions, batch.target.cuda())\n",
    "            acc = categorical_accuracy(predictions, batch.target.cuda())\n",
    "            epoch_loss += loss\n",
    "            epoch_acc += acc\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем w2v эмбединги обученные ранее для представления слов. Для этого сохраним в текстовом формате и построим словарь: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.Word2Vec.load(\"w2vmodel.model\")\n",
    "word2vec_model.wv.save_word2vec_format('w2v.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "vectors = Vectors(name='w2v.txt', cache='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/care1e55/.local/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# SOURCE.build_vocab(train, max_size=25000, vectors=\"glove.6B.100d\")\n",
    "SOURCE.build_vocab(train, max_size=25000, vectors=vectors)\n",
    "TARGET.build_vocab(train)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sort_key=lambda x: len(x.source), \n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view for debug\n",
    "# print(TARGET.vocab.stoi)\n",
    "# TARGET.vocab.freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверточная сеть с семинара. Изменения в размерности выходного слоя, т.к. теперь классификация не бинарная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels = 1, \n",
    "                out_channels = n_filters, \n",
    "                kernel_size = (fs, embedding_dim)\n",
    "            ) \n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [sent len, batch size]\n",
    "        text = text.permute(1, 0)\n",
    "        #text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SOURCE.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = len(TARGET.vocab)\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения сходимости используем stepLR scheduler.\n",
    "Используем CrossEntropyLoss, которая уже содержит в себе softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.51it/s]\n",
      "  0%|          | 2/477 [00:00<00:28, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 3.443, Train Acc: 16.64%, Val. Loss: 3.136, Val. Acc: 22.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.37it/s]\n",
      "  0%|          | 2/477 [00:00<00:30, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train Loss: 3.123, Train Acc: 23.39%, Val. Loss: 3.012, Val. Acc: 25.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.54it/s]\n",
      "  0%|          | 2/477 [00:00<00:29, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train Loss: 2.965, Train Acc: 26.09%, Val. Loss: 2.930, Val. Acc: 27.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.11it/s]\n",
      "  0%|          | 2/477 [00:00<00:28, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train Loss: 2.752, Train Acc: 30.14%, Val. Loss: 2.886, Val. Acc: 27.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.18it/s]\n",
      "  0%|          | 2/477 [00:00<00:28, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train Loss: 2.627, Train Acc: 32.70%, Val. Loss: 2.873, Val. Acc: 28.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.07it/s]\n",
      "  0%|          | 2/477 [00:00<00:28, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train Loss: 2.523, Train Acc: 35.02%, Val. Loss: 2.859, Val. Acc: 28.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.10it/s]\n",
      "  0%|          | 2/477 [00:00<00:32, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train Loss: 2.365, Train Acc: 38.18%, Val. Loss: 2.850, Val. Acc: 29.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.13it/s]\n",
      "  0%|          | 2/477 [00:00<00:28, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train Loss: 2.292, Train Acc: 39.80%, Val. Loss: 2.854, Val. Acc: 29.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.04it/s]\n",
      "  0%|          | 2/477 [00:00<00:31, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train Loss: 2.218, Train Acc: 41.37%, Val. Loss: 2.860, Val. Acc: 28.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.15it/s]\n",
      "  0%|          | 1/477 [00:00<00:49,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 2.134, Train Acc: 43.37%, Val. Loss: 2.858, Val. Acc: 29.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.14it/s]\n",
      "  0%|          | 2/477 [00:00<00:28, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 2.086, Train Acc: 44.56%, Val. Loss: 2.864, Val. Acc: 29.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.09it/s]\n",
      "  0%|          | 2/477 [00:00<00:29, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Loss: 2.053, Train Acc: 45.13%, Val. Loss: 2.871, Val. Acc: 29.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.09it/s]\n",
      "  0%|          | 2/477 [00:00<00:33, 14.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Loss: 2.004, Train Acc: 46.19%, Val. Loss: 2.871, Val. Acc: 28.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.14it/s]\n",
      "  0%|          | 2/477 [00:00<00:29, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Loss: 1.984, Train Acc: 46.70%, Val. Loss: 2.875, Val. Acc: 28.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:20<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Loss: 1.972, Train Acc: 46.92%, Val. Loss: 2.879, Val. Acc: 28.95%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_func(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate_func(model, valid_iterator, criterion)\n",
    "    scheduler.step()\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.856, Test Acc: 30.33%\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_acc = evaluate_func(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что получили качество лучше, чем baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/care1e55/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим дообработанные датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for file_path in ['training_fitered', 'dev_fitered', 'test_fitered']:\n",
    "    datasets[file_path] = pd.read_csv(\n",
    "        file_path, sep='\\t', header=None\n",
    "    )\n",
    "    datasets[file_path].columns=['location', 'target', 'source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для замены из wordnet и расширения датасета. Датасет будет содержить и оригинал, в остальных случаях если замена возможно - выбрать случайно из списка замен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonims(row):\n",
    "    result = []\n",
    "    for word in row.split():\n",
    "        try:\n",
    "            result.append(random.choice(random.choice(wn.synsets(word)).lemmas()).name())\n",
    "        except:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_dataset(dataset, factor=3):\n",
    "    for i in tqdm(range(factor)):\n",
    "        if i == 0:\n",
    "            result = dataset.copy(deep=True)\n",
    "            continue\n",
    "        current_dataset = dataset.copy(deep=True)\n",
    "        current_dataset['source'] = current_dataset['source'].apply(synonims)\n",
    "        result = result.append(current_dataset, ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся что функция работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:08<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "debug_test_dataset = extend_dataset(datasets['dev_fitered'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location                                      10873161.0.5925\n",
      "target                                                PROTEGO\n",
      "source      could kingsley vanished chair ronald sat erect...\n",
      "Name: 0, dtype: object\n",
      "location                                      10873161.0.5925\n",
      "target                                                PROTEGO\n",
      "source      could kingsley vanished chair ronald Sat rear ...\n",
      "Name: 7594, dtype: object\n",
      "location                                      10873161.0.5925\n",
      "target                                                PROTEGO\n",
      "source      could kingsley fly chair ronald sit put_up pro...\n",
      "Name: 15188, dtype: object\n"
     ]
    }
   ],
   "source": [
    "debug_test_dataset.shape\n",
    "print(debug_test_dataset.loc[0])\n",
    "print(debug_test_dataset.loc[7594])\n",
    "print(debug_test_dataset.loc[2*7594])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим с train выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:10<00:00, 23.54s/it]\n"
     ]
    }
   ],
   "source": [
    "new_train = extend_dataset(datasets['training_fitered'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv('new_training_fitered', sep=\"\\t\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем эксперимент обучив ту же модель с новым датасетом. Модель переобучается после 3ей эпохи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/care1e55/.local/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/care1e55/.local/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/care1e55/.local/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/care1e55/.local/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SOURCE = data.Field(tokenize='spacy')\n",
    "TARGET = data.LabelField()\n",
    "\n",
    "fields = [\n",
    "    (None, None),\n",
    "    ('target', TARGET),\n",
    "    ('source', SOURCE)\n",
    "]\n",
    "\n",
    "train, valid, test = data.TabularDataset.splits(\n",
    "    path = \"\",\n",
    "    train = 'new_training_fitered',\n",
    "    validation = 'dev_fitered',\n",
    "    test = 'test_fitered',\n",
    "    format = 'tsv',\n",
    "    fields = fields,\n",
    "    skip_header = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE.build_vocab(train, max_size=25000, vectors=\"glove.6B.100d\")\n",
    "SOURCE.build_vocab(train, max_size=25000, vectors=vectors)\n",
    "TARGET.build_vocab(train)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sort_key=lambda x: len(x.source), \n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SOURCE.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = len(TARGET.vocab)\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 714/714 [00:47<00:00, 15.18it/s]\n",
      "  0%|          | 0/714 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 3.164, Train Acc: 21.90%, Val. Loss: 2.954, Val. Acc: 27.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 714/714 [00:47<00:00, 15.16it/s]\n",
      "  0%|          | 1/714 [00:00<02:17,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train Loss: 2.840, Train Acc: 28.72%, Val. Loss: 2.858, Val. Acc: 29.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 714/714 [00:47<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train Loss: 2.628, Train Acc: 32.67%, Val. Loss: 2.830, Val. Acc: 30.29%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_func(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate_func(model, valid_iterator, criterion)\n",
    "    scheduler.step()\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.790, Test Acc: 30.59%\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_acc = evaluate_func(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать вывод, что качество примерно остается тем же, но улучшается скорость сходимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведен эксплоративный анализ и подсчитаны частоты слов и имен. Для корректного поиска именованых сущностей использвана модель Stanford NER.\n",
    "Произведена базовая обработка датасета - удалены стоп-слова и пунктуация, сделана лемматизация.\n",
    "Обучена модель представления слов word2vec с помощью пакета gensim, продемонстрировано как работает поиск синонимов, ассоциаций, лишних слов в обученной модели, а также получена визуализация пространства эмбедингов наиболее часто встречающихся слов с помощью CUDA-реализации алгоритма t-SNE.\n",
    "Обучена baseline модель fasstext для классификации, продемонстрировано улучшения качества после препроцессинга датасета. Обучена сверточная нейронная сеть для решенеия задачи мультиклассовой классификации, которая показала лучше качество, чем baseline. Датасет расширен аугментированными данными. Возможно дальнейшее улучшение модели, например использование LSTM или LSTM+CNN, Transformer.\n",
    "При решении задачи немного помогло знание предметной области при опредлении валидных именованых сущностей, но, кажется знание предметной области не обязательно для решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
